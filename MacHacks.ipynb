{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dvip07/MacHacks/blob/Main/MacHacks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1wryXLXDFCw"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution graphs (histogram/bar graph) of column data\n",
        "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):\n",
        "    nunique = df.nunique()\n",
        "    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values\n",
        "    nRow, nCol = df.shape\n",
        "    columnNames = list(df)\n",
        "    nGraphRow = (nCol + nGraphPerRow - 1) / nGraphPerRow\n",
        "    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')\n",
        "    for i in range(min(nCol, nGraphShown)):\n",
        "        plt.subplot(nGraphRow, nGraphPerRow, i + 1)\n",
        "        columnDf = df.iloc[:, i]\n",
        "        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):\n",
        "            valueCounts = columnDf.value_counts()\n",
        "            valueCounts.plot.bar()\n",
        "        else:\n",
        "            columnDf.hist()\n",
        "        plt.ylabel('counts')\n",
        "        plt.xticks(rotation = 90)\n",
        "        plt.title(f'{columnNames[i]} (column {i})')\n",
        "    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ZJFgkmLGDumq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation matrix\n",
        "def plotCorrelationMatrix(df, graphWidth):\n",
        "    filename = df.dataframeName\n",
        "    df = df.dropna('columns') # drop columns with NaN\n",
        "    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n",
        "    if df.shape[1] < 2:\n",
        "        print(f'No correlation plots shown: The number of non-NaN or constant columns ({df.shape[1]}) is less than 2')\n",
        "        return\n",
        "    corr = df.corr()\n",
        "    plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')\n",
        "    corrMat = plt.matshow(corr, fignum = 1)\n",
        "    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
        "    plt.yticks(range(len(corr.columns)), corr.columns)\n",
        "    plt.gca().xaxis.tick_bottom()\n",
        "    plt.colorbar(corrMat)\n",
        "    plt.title(f'Correlation Matrix for {filename}', fontsize=15)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "bcazQ8-nD4Zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter and density plots\n",
        "def plotScatterMatrix(df, plotSize, textSize):\n",
        "    df = df.select_dtypes(include =[np.number]) # keep only numerical columns\n",
        "    # Remove rows and columns that would lead to df being singular\n",
        "    df = df.dropna('columns')\n",
        "    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n",
        "    columnNames = list(df)\n",
        "    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots\n",
        "        columnNames = columnNames[:10]\n",
        "    df = df[columnNames]\n",
        "    ax = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')\n",
        "    corrs = df.corr().values\n",
        "    for i, j in zip(*plt.np.triu_indices_from(ax, k = 1)):\n",
        "        ax[i, j].annotate('Corr. coef = %.3f' % corrs[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)\n",
        "    plt.suptitle('Scatter and Density Plot')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "cGBv0qFxD8Hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "background = None\n",
        "accumulated_weight = 0.5\n",
        "\n",
        "ROI_top = 100\n",
        "ROI_bottom = 300\n",
        "ROI_right = 150\n",
        "ROI_left = 350\n",
        "\n",
        "\n",
        "def cal_accum_avg(frame, accumulated_weight):\n",
        "\n",
        "    global background\n",
        "    \n",
        "    if background is None:\n",
        "        background = frame.copy().astype(\"float\")\n",
        "        return None\n",
        "\n",
        "    cv2.accumulateWeighted(frame, background, accumulated_weight)\n",
        "\n",
        "\n",
        "def segment_hand(frame, threshold=25):\n",
        "    global background\n",
        "    \n",
        "    diff = cv2.absdiff(background.astype(\"uint8\"), frame)\n",
        "\n",
        "    _ , thresholded = cv2.threshold(diff, threshold, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Grab the external contours for the image\n",
        "    image, contours, hierarchy = cv2.findContours(thresholded.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    if len(contours) == 0:\n",
        "        return None\n",
        "    else:\n",
        "        \n",
        "        hand_segment_max_cont = max(contours, key=cv2.contourArea)\n",
        "        \n",
        "        return (thresholded, hand_segment_max_cont)\n",
        "\n",
        "\n",
        "cam = cv2.VideoCapture(0)\n",
        "\n",
        "num_frames = 0\n",
        "element = 10\n",
        "num_imgs_taken = 0\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "#     frame_copy = frame.copy()\n",
        "while True:\n",
        "    success, img = cap.read()\n",
        "    if img is None:\n",
        "        break\n",
        "    imgResult = img.copy()\n",
        "\n",
        "\n",
        "    roi = frame[ROI_top:ROI_bottom, ROI_right:ROI_left]\n",
        "\n",
        "    gray_frame = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
        "    gray_frame = cv2.GaussianBlur(gray_frame, (9, 9), 0)\n",
        "\n",
        "    if num_frames < 60:\n",
        "        cal_accum_avg(gray_frame, accumulated_weight)\n",
        "        if num_frames <= 59:\n",
        "            \n",
        "            cv2.putText(frame_copy, \"FETCHING BACKGROUND...PLEASE WAIT\", (80, 400), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,255), 2)\n",
        "            #cv2.imshow(\"Sign Detection\",frame_copy)\n",
        "         \n",
        "    #Time to configure the hand specifically into the ROI...\n",
        "    elif num_frames <= 300: \n",
        "\n",
        "        hand = segment_hand(gray_frame)\n",
        "        \n",
        "        cv2.putText(frame_copy, \"Adjust hand...Gesture for\" + str(element), (200, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
        "        \n",
        "        # Checking if hand is actually detected by counting number of contours detected...\n",
        "        if hand is not None:\n",
        "            \n",
        "            thresholded, hand_segment = hand\n",
        "\n",
        "            # Draw contours around hand segment\n",
        "            cv2.drawContours(frame_copy, [hand_segment + (ROI_right, ROI_top)], -1, (255, 0, 0),1)\n",
        "            \n",
        "            cv2.putText(frame_copy, str(num_frames)+\"For\" + str(element), (70, 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
        "\n",
        "            # Also display the thresholded image\n",
        "            cv2.imshow(\"Thresholded Hand Image\", thresholded)\n",
        "    \n",
        "    else: \n",
        "        \n",
        "        # Segmenting the hand region...\n",
        "        hand = segment_hand(gray_frame)\n",
        "        \n",
        "        # Checking if we are able to detect the hand...\n",
        "        if hand is not None:\n",
        "            \n",
        "            # unpack the thresholded img and the max_contour...\n",
        "            thresholded, hand_segment = hand\n",
        "\n",
        "            # Drawing contours around hand segment\n",
        "            cv2.drawContours(frame_copy, [hand_segment + (ROI_right, ROI_top)], -1, (255, 0, 0),1)\n",
        "            \n",
        "            cv2.putText(frame_copy, str(num_frames), (70, 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
        "            #cv2.putText(frame_copy, str(num_frames)+\"For\" + str(element), (70, 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
        "            cv2.putText(frame_copy, str(num_imgs_taken) + 'images' +\"For\" + str(element), (200, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
        "            \n",
        "            # Displaying the thresholded image\n",
        "            cv2.imshow(\"Thresholded Hand Image\", thresholded)\n",
        "            if num_imgs_taken <= 300:\n",
        "                #cv2.imwrite(r\"D:\\\\gesture\\\\train\\\\\"+str(element)+\"\\\\\" + str(num_imgs_taken+300) + '.jpg', thresholded)\n",
        "                cv2.imwrite(r\"D:\\\\gesture\\\\x\"+\"\\\\\" + str(num_imgs_taken) + '.jpg', thresholded)\n",
        "            else:\n",
        "                break\n",
        "            num_imgs_taken +=1\n",
        "        else:\n",
        "            cv2.putText(frame_copy, 'No hand detected...', (200, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
        "\n",
        "    # Drawing ROI on frame copy\n",
        "    cv2.rectangle(frame_copy, (ROI_left, ROI_top), (ROI_right, ROI_bottom), (255,128,0), 3)\n",
        "    \n",
        "    cv2.putText(frame_copy, \"DataFlair hand sign recognition_ _ _\", (10, 20), cv2.FONT_ITALIC, 0.5, (51,255,51), 1)\n",
        "    \n",
        "    # increment the number of frames for tracking\n",
        "    num_frames += 1\n",
        "\n",
        "    # Display the frame with segmented hand\n",
        "    cv2.imshow(\"Sign Detection\", frame_copy)\n",
        "\n",
        "    # Closing windows with Esc key...(any other key with ord can be used too.)\n",
        "    k = cv2.waitKey(10) & 0xFF\n",
        "\n",
        "    if k == 27:\n",
        "        break\n",
        "\n",
        "# Releasing camera & destroying all the windows...\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "cam.release()"
      ],
      "metadata": {
        "id": "OZ1AnXPVEGW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.vision.all import *\n",
        "from fastai.vision.widgets import *\n",
        "\n",
        "from PIL import Image\n",
        "import sys\n",
        "\n",
        "learn_inf = learn_inf=torch.load('model/res34.pkl')\n",
        "def predict(img):\n",
        " \n",
        "  l,p,j=learn_inf.predict(PILImage.create(img))\n",
        "  return l,j[p].item()*100\n",
        "\n",
        "\n",
        "files=[]\n",
        "images=glob.glob('Test Images/*.jpg')\n",
        "\n",
        "for i in images:\n",
        "  print(predict(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "DXg2cVD9JTGY",
        "outputId": "9c2810cb-cd40-4d54-abd1-7a7e307c82ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-ab90c155fd3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidgets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/vision/all.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0maugment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fastai.callbacks.all'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}